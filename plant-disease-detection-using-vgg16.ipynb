{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Loading the Packages","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport sys\nimport os\nfrom keras.applications.vgg16 import VGG16\nimport keras\nfrom numpy import load\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import train_test_split\nfrom keras import backend\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.layers import Dropout\nfrom keras.layers.normalization import BatchNormalization","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Preprocessing","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\ntraindir = \"../input/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/train\"\nvaliddir = \"../input/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/valid\"\ntestdir = \"../input/new-plant-diseases-dataset/test/test\"\n\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   fill_mode='nearest')\n\nvalid_datagen = ImageDataGenerator(rescale=1./255)\n\nbatch_size = 128\ntraining_set = train_datagen.flow_from_directory(traindir,\n                                                 target_size=(224, 224),\n                                                 batch_size=batch_size,\n                                                 class_mode='categorical')\n\nvalid_set = valid_datagen.flow_from_directory(validdir,\n                                            target_size=(224, 224),\n                                            batch_size=batch_size,\n                                            class_mode='categorical')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_dict = training_set.class_indices\nprint(class_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"li = list(class_dict.keys())\nprint(li)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_num = training_set.samples\nvalid_num = valid_set.samples","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Preparation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model=VGG16(include_top=False,input_shape=(224,224,3))\nbase_model.trainable=False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier=keras.models.Sequential()\nclassifier.add(base_model)\nclassifier.add(Flatten())\nclassifier.add(Dense(38,activation='softmax'))\nclassifier.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fitting images to CNN\nhistory = classifier.fit(training_set,\n                         steps_per_epoch=train_num//batch_size,\n                         validation_data=valid_set,\n                         epochs=5,\n                         validation_steps=valid_num//batch_size,\n                         )\n#saving model\n#filepath=\"Mymodel.hdf5\"\n#model.save(filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Saving our model\nfilepath=\"Mymodel.h5\"\nclassifier.save(filepath)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualizing the Accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, acc, color='green', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n#loss plot\nplt.plot(epochs, loss, color='pink', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting an image\nfrom keras.preprocessing import image\nimport numpy as np\nimage_path = \"../input/new-plant-diseases-dataset/test/test/TomatoEarlyBlight1.JPG\"\nnew_img = image.load_img(image_path, target_size=(224, 224))\nimg = image.img_to_array(new_img)\nimg = np.expand_dims(img, axis=0)\nimg = img/255\n\nprint(\"Following is our prediction:\")\nprediction = classifier.predict(img)\n# decode the results into a list of tuples (class, description, probability)\n# (one such list for each sample in the batch)\nd = prediction.flatten()\nj = d.max()\nfor index,item in enumerate(d):\n    if item == j:\n        class_name = li[index]\n\n#ploting image with predicted class name        \nplt.figure(figsize = (4,4))\nplt.imshow(new_img)\nplt.axis('off')\nplt.title(class_name)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}